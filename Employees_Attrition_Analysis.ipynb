{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P73oorEYFmmJ"
   },
   "source": [
    "# **Dataset context**\n",
    "\n",
    "The **IBM HR Analytics Employee Attrition & Performance** dataset provides a fictional snapshot of an organization's workforce aimed at helping HR teams and data analysts identify the factors that contribute to employee turnover and performance trends. It features both demographic and job-related variables, enabling the development of predictive models and strategic insights to improve employee retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GROeh4hFG7iZ"
   },
   "source": [
    "# **Dataset content**\n",
    "There are 1,470 observations and 35 variables, including:\n",
    "\n",
    "\n",
    "*   **Age, Gender, MaritalStatus, Education, EducationField** — employee demographics\n",
    "\n",
    "*   **Department, JobRole, BusinessTravel, OverTime** — job characteristics and work patterns\n",
    "\n",
    "*   **DistanceFromHome, EnvironmentSatisfaction, JobSatisfaction, WorkLifeBalance, RelationshipSatisfaction** — job experience and well‑being\n",
    "\n",
    "*   **MonthlyIncome, HourlyRate, PercentSalaryHike, StockOptionLevel** — compensation info\n",
    "\n",
    "*   **TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager, NumCompaniesWorked, TrainingTimesLastYear** — career progression & training metrics\n",
    "*   **PerformanceRating, JobInvolvement** — performance indicators\n",
    "\n",
    "*   **DailyRate, MonthlyRate, StandardHours, EmployeeCount, EmployeeNumber, Over18** — various administrative identifiers; some hold constant values and are often dropped during preprocessing\n",
    "\n",
    "*   **Attrition** — the target variable: whether the employee left (“Yes”/“No”)\n",
    "\n",
    "*(source: https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn preprocessing and model selection\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline as SklearnPipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Imbalanced-learn preprocessing\n",
    "import imblearn\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Classifiers\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Metrics and evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "from sklearn.metrics._plot.precision_recall_curve import precision_recall_curve\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['OMP_NUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDNNRvQnKYqg"
   },
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4bWWwFgKdxf"
   },
   "outputs": [],
   "source": [
    "def crosstab_categorical(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Print crosstabs of 'Attrition' vs. each categorical column in df_cat_col.\"\"\"\n",
    "    for col in df_cat_col:\n",
    "        print(pd.crosstab(df['Attrition'], df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OI4D9ofRKtWs"
   },
   "outputs": [],
   "source": [
    "def cap_upper_iqr(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Caps only the upper outliers in specified columns using the IQR method.\n",
    "    \"\"\"\n",
    "    df_capped = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_capped[col] = df[col].clip(upper=upper_bound)  # No lower bound applied\n",
    "    return df_capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8gbAAVLNphS"
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_df(\n",
    "    pipeline: SklearnPipeline,\n",
    "    preprocessor: ColumnTransformer\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts feature importances from a model pipeline.\n",
    "    \"\"\"\n",
    "    model: BaseEstimator = pipeline.named_steps['model']\n",
    "    feature_names = []\n",
    "\n",
    "    for name, transformer, columns in preprocessor.transformers_:\n",
    "        if name != 'remainder':\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                transformed_names = transformer.get_feature_names_out(columns)\n",
    "            else:\n",
    "                transformed_names = columns\n",
    "            feature_names.extend(transformed_names)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOAevOA-eQgN"
   },
   "outputs": [],
   "source": [
    "def compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate key classification metrics for train and test data.\n",
    "    Returns a dictionary with confusion matrix, accuracy, precision,\n",
    "    recall, F1 score, ROC AUC, and average precision.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    metrics = {\n",
    "        'confusion_matrix': (tn, fp, fn, tp),\n",
    "        'accuracy_train': accuracy_score(y_train, y_pred_tr),\n",
    "        'accuracy_test': accuracy_score(y_test, y_pred),\n",
    "        'precision_train': precision_score(y_train, y_pred_tr, average='binary'),\n",
    "        'precision_test': precision_score(y_test, y_pred, average='binary'),\n",
    "        'recall_train': recall_score(y_train, y_pred_tr),\n",
    "        'recall_test': recall_score(y_test, y_pred),\n",
    "        'f1_train': f1_score(y_train, y_pred_tr),\n",
    "        'f1_test': f1_score(y_test, y_pred),\n",
    "        'roc_auc_test': roc_auc_score(y_test, y_pred),\n",
    "        'average_precision_test': average_precision_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLLGUkukfrY8"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, X_test, y_test) -> None:\n",
    "    \"\"\"\n",
    "    Display ROC curve for a trained classifier.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    RocCurveDisplay.from_estimator(model, X_test, y_test, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgPCLPhygPxD"
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(model, X_test, y_test) -> None:\n",
    "    \"\"\"\n",
    "    Plot the Precision-Recall curve with average precision.\n",
    "    \"\"\"\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_scores)\n",
    "    avg_precision = average_precision_score(y_test, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(rec, prec, label=f'Average precision-recall score: {avg_precision:.2f}')\n",
    "    plt.title('Precision-Recall Curve', size=20)\n",
    "    plt.xlabel('Recall', size=14)\n",
    "    plt.ylabel('Precision', size=14)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFLYDX_Thr7j"
   },
   "outputs": [],
   "source": [
    "def create_model_summary_row(model_name: str, metrics: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a summary dictionary for classification model performance.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = metrics['confusion_matrix']\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'tp': tp,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'correct': tp + tn,\n",
    "        'incorrect': fp + fn,\n",
    "        'accuracy_train': metrics['accuracy_train'],\n",
    "        'accuracy_test': metrics['accuracy_test'],\n",
    "        'precision_train': metrics['precision_train'],\n",
    "        'precision_test': metrics['precision_test'],\n",
    "        'recall_train': metrics['recall_train'],\n",
    "        'recall_test': metrics['recall_test'],\n",
    "        'f1_train': metrics['f1_train'],\n",
    "        'f1_test': metrics['f1_test'],\n",
    "        'roc_auc': metrics['roc_auc_test'],\n",
    "        'avg_pre': round(metrics['average_precision_test'], 3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDle1tyKHI9_"
   },
   "source": [
    "# **Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3HZ2GJRHnu5"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/content/drive/MyDrive/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "df = pd.read_csv(\"./data/WA_Fn-UseC_-HR-Employee-Attrition.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77A_k1rWIhST"
   },
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2NeFLEBHIj2o",
    "outputId": "cee9fdf9-01ee-46a6-970c-357bb18dd1cf"
   },
   "outputs": [],
   "source": [
    "# Shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "cpNiQjEMInEv",
    "outputId": "59583440-eff7-48b6-8085-7d2f55aeab8a"
   },
   "outputs": [],
   "source": [
    "# First 5 rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "r4-uQmmfIrOX",
    "outputId": "ccb056d9-c2b5-43cf-b27e-59e79beed4fe"
   },
   "outputs": [],
   "source": [
    "# Last 5 rows of data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kGjko-o1ItOX",
    "outputId": "8417f45d-08b1-4ab2-ef39-1d0d57bc7a7c"
   },
   "outputs": [],
   "source": [
    "# Check duplicates - there are no duplicates\n",
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NunRPU8iI0yp",
    "outputId": "68103578-d2fc-4eb8-c6c9-3b61d4aa6c39"
   },
   "outputs": [],
   "source": [
    "# Columns names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZDt_4c3EI_jv",
    "outputId": "590bb937-abdb-4785-e677-445e0530f40f"
   },
   "outputs": [],
   "source": [
    "# Data types - there are categorical and numerical columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VEqQNI14JEXp",
    "outputId": "1e81cc77-7698-4ddc-8758-c1e83de532c0"
   },
   "outputs": [],
   "source": [
    "# Unique values in each column\n",
    "pd.Series({c: df[c].unique() for c in df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "W1BR1FD5JIRA",
    "outputId": "cb13d48f-506d-4591-bf2d-a99e5a27c772"
   },
   "outputs": [],
   "source": [
    "# Number of unique values for each column - some columns have few unque values whereas others - almost for each row\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdeseuvWJLJU",
    "outputId": "8b73bb36-77e9-4ee9-b13e-4334ba3281e9"
   },
   "outputs": [],
   "source": [
    "# Check missing values - no missing values\n",
    "sum(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c_ooqfHJSM1",
    "outputId": "30b5b426-9bc4-4dd8-fb51-067d2c7d99c2"
   },
   "outputs": [],
   "source": [
    "# Data details\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "Rsi-6X1nJb-Z",
    "outputId": "cf8ad908-4b75-42e9-fa16-af38113fcb9c"
   },
   "outputs": [],
   "source": [
    "# Dataset is completely imbalanced - 1233 employees stayed at company vs 237 left\n",
    "df['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7Nl7IpDdJrqP",
    "outputId": "b806cb2f-f954-41f1-ee5c-349558ff30b3"
   },
   "outputs": [],
   "source": [
    "# The further distance from home, the less employees are in the company from this particular area\n",
    "df['DistanceFromHome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "ecWSYSvnJyZ5",
    "outputId": "e5c8f8a0-e498-443e-d411-2b7f4b00cf44"
   },
   "outputs": [],
   "source": [
    "# The most employees work at R&D Department, the least - in HR\n",
    "df['Department'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvgu3kE2J-Gf"
   },
   "outputs": [],
   "source": [
    "# Drop columns  - no significant meaning for further analysis\n",
    "# Column EmployeCount represents the amount of employees with particular EmployeeNumber - it is always 1\n",
    "# Each employee is Over18\n",
    "# Each emlpoyee works 80 hours - column StandardHours\n",
    "df.drop(columns=['EmployeeCount', 'Over18', 'EmployeeNumber', 'StandardHours'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3acaMGE-KBso"
   },
   "outputs": [],
   "source": [
    "# Change the type for columns to categorical\n",
    "for col in ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus']: \n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrphNqFuTHlI"
   },
   "outputs": [],
   "source": [
    "# Change the type for columns to binary\n",
    "df['Attrition'] = np.where(df['Attrition'] == 'Yes', 1, 0)\n",
    "df['Gender'] = np.where(df['Gender'] == 'Female', 1, 0)\n",
    "df['OverTime'] = np.where(df['OverTime'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQrEBoq6KC_g",
    "outputId": "f0d1997d-1fd2-4125-aeb9-2f64811b5352"
   },
   "outputs": [],
   "source": [
    "# Check the details after change - less memory usage\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mkms9OGSKPf-",
    "outputId": "e25ab6bd-91c0-4964-bfe0-05fe78ae644e"
   },
   "outputs": [],
   "source": [
    "# Statistics for categorical data\n",
    "df.describe(include='category').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "qsRkQ-AjKgY_",
    "outputId": "3f6d0fa9-6fde-4609-e161-44aeeb6561c3"
   },
   "outputs": [],
   "source": [
    "# Statistics for numerical data - the highest valuesare highlighted in red\n",
    "df_num_col = df.select_dtypes(exclude=['category']).columns\n",
    "df_num = df[df_num_col]\n",
    "desc_stats = df_num.describe()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(desc_stats, cmap='Oranges', annot=True, fmt=\".2f\", cbar=True)\n",
    "plt.title(\"Descriptive Statistics Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbJfCagHKr2P",
    "outputId": "c07ce507-3d06-44a5-fa6b-189f591d37d8"
   },
   "outputs": [],
   "source": [
    "# Present cross tabs for all categorical columns separately\n",
    "df_cat_col = df.select_dtypes(include=['category']).columns\n",
    "crosstab_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBOGl8kQMbLq",
    "outputId": "49432188-d25d-4536-fcb1-15eb123c35bb"
   },
   "outputs": [],
   "source": [
    "# The percentage of employees who left and stayed\n",
    "df['Attrition'] = df['Attrition'].astype(int)\n",
    "print('Stay:', round(df['Attrition'].value_counts()[0] / len(df) * 100, 2), '% of the dataset')\n",
    "print('Left:', round(df['Attrition'].value_counts()[1] / len(df) * 100, 2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojdw8MvqM94e"
   },
   "source": [
    "# **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "GlSQoQwwNJ4Y",
    "outputId": "da0c693f-350f-481e-d802-326c1f1d8e31"
   },
   "outputs": [],
   "source": [
    "# Based on below bar chart for Attrition column, dataset is not well balanced (84% stay vs 16% leave)\n",
    "left = (df[df['Attrition'] == 1]).count()\n",
    "stay = (df[df['Attrition'] == 0]).count()\n",
    "data = [left[0], stay[0]]\n",
    "labels = ['Leave', 'Stay']\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title('Employees who left vs employees who stayed')\n",
    "bars = plt.bar(labels, data, color='green', edgecolor='black')\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, str(yval), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "9s-v6SrQNS58",
    "outputId": "05437ed0-51d8-47e5-a0b3-cbf2277ab044"
   },
   "outputs": [],
   "source": [
    "# The most people are married, the least - divorced\n",
    "marital_status = df['MaritalStatus'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(data=df, x='MaritalStatus')\n",
    "plt.title('Proportion of Marital Statuses')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "total = len(df['MaritalStatus'])\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    percentage = (height / total) * 100\n",
    "    ax.annotate(f'{percentage:.2f}%', (p.get_x() + p.get_width() / 2, height),\n",
    "                ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "7UKcZA4LbeBB",
    "outputId": "b43977d1-ddff-4d4c-bbe4-2f5134ff25ab"
   },
   "outputs": [],
   "source": [
    "# Total working years distribution\n",
    "sns.histplot(df['TotalWorkingYears'], kde=True, bins=10, color='lightgreen')\n",
    "plt.title(\"Total working year distribution\")\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Total working years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yojr5h4QbfPQ"
   },
   "source": [
    "*   The distribution is not symmetric - it has long tail to the right - most employees have fewer years of experience, while a few have a lot.\n",
    "*   The most common total working experience falls in the 8-10 year range - workforce consisted of mid-career professionals.\n",
    "*   The count drop significantly after 15 years of experience - it is possible that fewer employees stay in the company long enough to reach higher salary.\n",
    "*   Very experienced people are very rare in the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_-W5ZNBcOXW4",
    "outputId": "a4a3384d-4cb3-4a47-8fe3-5c390dd834d4"
   },
   "outputs": [],
   "source": [
    "# Plot numeric correlation with heatmap\n",
    "corr = df.select_dtypes(exclude=['category']).corr()\n",
    "plt.figure(figsize=(20, 20))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, annot = True, mask=mask, cmap = 'coolwarm', fmt = \".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3grDntUPJSer"
   },
   "source": [
    "## **Remarks for correlation with Attrition column**\n",
    "\n",
    "*   JobInvolvement has one of the moderate negative correlaction wit attrition level at -0.13.\n",
    "*   Changes in attrition level can be explained by about 3% changes in JobLevel.\n",
    "*   MonthlyIncome has negative correlation with attrition level at -0.16.\n",
    "*   Changes in attrition level can be explained by about 6% changes in OverTime. This correlation is the biggest.\n",
    "*   StockOptionLevel, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsWithCurrManager have also negative correcaltion with attrition level at -0.14, -0.17, -0.13, -0.16 and -0.16 accordingly.\n",
    "\n",
    "## **Remarks for other correlations**\n",
    "\n",
    "*   There is strong correlation (above 0.7) between following columns: MonthlyIncome/JobLevel, TotalWorkingYears/JobLevel, TotalWorkingYears/MonthlyIncome, PerformanceRating/PercentSalaryHike, YearsInCurrentRole/YearsAtCompany, YearsWithCurrManager/YearAtCompany, YearsWithCurrManager/YearsInCurrentRole.\n",
    "*   However, one correlation is extremly high - between MonthlyIncome and JobLevel. Due to this fact, MonthlyIncome column will be eliminated from further analysis to make the form filled quicker.\n",
    "* Columns:\n",
    " - NumCompaniesWorked, abs correlation 0.04\n",
    " - Education, Gender, YearsSinceLastPromotion, abs correlation 0.03\n",
    " - MonthlyRate, abs correlation 0.02\n",
    " - HourlyRate, PercentSalaryHike, abs correlation 0.01\n",
    " - PerformanceRating, correlation 0.00\n",
    "\n",
    " are weakly correlated with attrition level. The model without them will be considered.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cK6a40c7cN_Z",
    "outputId": "d39916b6-47cb-47ba-ad6f-0b03e112c7f8"
   },
   "outputs": [],
   "source": [
    "# Distribution plots for all numerical features\n",
    "excluded_col = 'Attrition'\n",
    "filtered_columns = [col for col in df_num_col if col != excluded_col]\n",
    "\n",
    "for c in df_num_col:\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.histplot(data=df, x=c, hue=excluded_col, kde=True, stat='count', alpha=0.6, palette='Set2')\n",
    "    plt.title(f\"Distribution of {c} by {excluded_col}\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HtvUbvyV4kT"
   },
   "source": [
    "\n",
    "\n",
    "*  JobInvolvement - employees with medium job involvement are more likely to quit.\n",
    "*  JobLevel - employees at lower job levels are more likely to leave, possibly due to lack of satisfaction, compensation or growth.\n",
    "*  MonthlyIncome - workers with lower income are more prone to leave the company.\n",
    "*  StockOptionLevel - no stock options might be a factor contributing to employee leaving.\n",
    "*  TotalWorkingYears - less experienced employees are mote prone to leaving. They may explore career options or seek better opportunities.\n",
    "*  YearsIiCurrentRole - short tenure is a red flag. It can indicate role misfit or lack of progression.\n",
    "*  YearsWithCurrManager - the attrition is more possible for workers who spend less years with current manager.\n",
    "*  YearsAtCompany - newer employees are at higher risk of attrition. The first few years are critical.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLmvF6XiNLnY"
   },
   "source": [
    "# **Outliers detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ5GlzCeQaTw"
   },
   "outputs": [],
   "source": [
    "# Split the data into numerical and categorical columns\n",
    "num_attr = df.select_dtypes(include='number').columns\n",
    "cat_attr = df.select_dtypes(include='category').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-eM0iVtJ-_A"
   },
   "outputs": [],
   "source": [
    "# Numerical columns to be capped based on distribution on upper sight: YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager\n",
    "columns = ['YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "df_capped = cap_upper_iqr(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Visn1qAoecuf",
    "outputId": "2d56a1b0-e88c-43f0-a45a-47f89d75bfdb"
   },
   "outputs": [],
   "source": [
    "# The comparison for columns before and after capping\n",
    "for col in columns:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Original\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(x=df[col], color='salmon')\n",
    "    plt.title(f\"{col} - Original\")\n",
    "\n",
    "    # Capped\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df_capped[col], color='lightblue')\n",
    "    plt.title(f\"{col} - IQR Capped\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHZKwf1oZsNf"
   },
   "source": [
    "## **Remarks for possible outliers**\n",
    "\n",
    "\n",
    "*   Columns YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrentManager might have outliers.\n",
    "* The outliers are floored using first and third quartile for extreme value.  Thanks to this operation for upper bound, the outliers are reduced without removing rows and the dataset size remains constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6kymQ78Aat1"
   },
   "source": [
    "# **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_yQUr21y-SW",
    "outputId": "6d76c86a-a3a1-43ca-8f96-f2db30155ca8"
   },
   "outputs": [],
   "source": [
    "# Dataset without MonthlyIncome and other weekly correlated with attrition features\n",
    "df_shrink = df.drop(columns=['MonthlyIncome', 'NumCompaniesWorked', 'Education', 'Gender', 'YearsSinceLastPromotion', 'MonthlyRate', 'HourlyRate', 'PercentSalaryHike', 'PerformanceRating'])\n",
    "df_shrink.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxjI5O-8iLdP",
    "outputId": "42f1625d-8e11-4391-8ff0-c125e2bbdacd"
   },
   "outputs": [],
   "source": [
    "# Verify categorical and numerical attributes content for original dataset\n",
    "print('Numerical attributes:', num_attr)\n",
    "print('Categorical attributes:', cat_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26O6vMJS0seN"
   },
   "outputs": [],
   "source": [
    "# Split the shrink data into numerical and categorical columns\n",
    "num_attr_shrink = df_shrink.select_dtypes(include='number').columns\n",
    "cat_attr_shrink = df_shrink.select_dtypes(include='category').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "If9fqyuX2ufT",
    "outputId": "31e9416a-71e2-4d99-ec76-24f7b9e4cbe1"
   },
   "outputs": [],
   "source": [
    "# Verify categorical and numerical attributes content for shrink dataset\n",
    "print('Numerical attributes:', num_attr_shrink)\n",
    "print('Categorical attributes:', cat_attr_shrink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBD4_SQoA6Jv"
   },
   "outputs": [],
   "source": [
    "# Column transformer to preprocess numeric and categorical columns\n",
    "excluded_column = 'Attrition'\n",
    "num_attr_except_one = [col for col in num_attr if col != excluded_column]\n",
    "all_attr = list(num_attr) + list(cat_attr)\n",
    "\n",
    "num_attr_shrink_except_one = [col for col in num_attr_shrink if col != excluded_column]\n",
    "all_attr_shrink = list(num_attr_shrink) + list(cat_attr_shrink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLREIbkcib2O"
   },
   "outputs": [],
   "source": [
    "# Column transformer to preprocess numeric and categorical columns\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_attr_except_one),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_attr)\n",
    "])\n",
    "\n",
    "preprocessor_shrink = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_attr_shrink_except_one),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_attr_shrink)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9cpiipZsWPJ"
   },
   "outputs": [],
   "source": [
    "# Function to get pipeline with any model\n",
    "def get_model_pipeline(model):\n",
    "    return SklearnPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyaZBEEpP0tg"
   },
   "source": [
    "# **Modellling for original dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEQL3J1wYrHg"
   },
   "outputs": [],
   "source": [
    "# Retrieving columns which will represent independent/dependent variables\n",
    "X = df.drop(['Attrition'], axis = 1)\n",
    "y = df[['Attrition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Q2bbcLcYxH2"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=True, stratify=y, random_state = 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCFqCZLJycXb"
   },
   "source": [
    "## **Logistic Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "oYsew9qXBRD2",
    "outputId": "04383a81-7d4b-4df1-a587-925bee3f55a3"
   },
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "model_1 = get_model_pipeline(LogisticRegression())\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = model_1.predict(X_test)\n",
    "y_pred_tr = model_1.predict(X_train)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfLCC2mHDZFj",
    "outputId": "695d9ca0-5379-455a-f664-8af0c550019a"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqLIGRvcMfa2",
    "outputId": "5f801148-716e-422f-9d6d-8199ee862c1b"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wBIRU6fgzeRd",
    "outputId": "8d8ae57c-7742-44f2-cc6a-a23e2e9a5ac6"
   },
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "\n",
    "# Extract feature names from each transformer in the ColumnTransformer\n",
    "for name, transformer, columns in preprocessor.transformers_:\n",
    "    if name != 'remainder':\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            transformed_names = transformer.get_feature_names_out(columns)\n",
    "        else:\n",
    "            transformed_names = columns\n",
    "        feature_names.extend(transformed_names)\n",
    "\n",
    "m1 = model_1.named_steps['model']\n",
    "importances = m1.coef_[0]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - Logistic regression')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45GBpp70Zmke"
   },
   "source": [
    "\n",
    "*  We can expect that odds of people who left the company to increase (the original coefficient is positive) for features: OverTime, BusinessTravel_Travel_Frequently, EducationField_Technical Degree, JobRole_Sales Representative, JobRole_Laboratory Technician, YearsAtCompany, MaritalStatus_Single, DistanceFromHome, NumCompaniesWorked, YearsSinceLastPromotion, JobRole_Human Resources, Department_Sales, EducationField_HumanResources, EducationField_Marketing, HourlyRate, MonthlyRate, BusinessTravel_Travel Rarely, JobRole_Manager, PercentSalaryHike, Education, JobLevel and JobRole_Sales Executive.\n",
    "*   OverTime, BusinessTravel_Travel_Frequently and EducationField_Technical Degree are the strongest predictors.\n",
    "*   PerformanceRating and JobRole_Sales Executive are the weakest predictors.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HwPHJ8AMxin"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_1 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "VSSxjuvhM1YQ",
    "outputId": "3881ef19-d740-4666-b63d-882f457056f1"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(model_1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1ctQJYaTeQO"
   },
   "source": [
    "AUC is 0.87 which means that there is a 87% chance that the model will be able to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "ayTU6PUTM6m8",
    "outputId": "7a0475b7-a513-46c2-be4f-48beacfa75e3"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(model_1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ovwwmhu5ckG_"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_1 = create_model_summary_row(\"Logistic Regression\", metrics_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ03ac4Uc2tc"
   },
   "source": [
    "## **Random Forest model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "ryNLRRtuTle6",
    "outputId": "7584dd50-750f-4349-9f4e-42e9d5e78a83"
   },
   "outputs": [],
   "source": [
    "# Random Forest Classifier model\n",
    "model_2 = get_model_pipeline(RandomForestClassifier())\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = model_2.predict(X_test)\n",
    "y_pred_tr = model_2.predict(X_train)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vb4S01gPTpyI",
    "outputId": "3d0a1921-3ed1-45b3-99c1-8ab3b880788d"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgnQz1MPTp1p",
    "outputId": "9d5985eb-11a8-435a-da23-d3e649418c5f"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sveaHhKeWpYb",
    "outputId": "7ae4c4a8-f60e-4896-c2a1-0e16644944d9"
   },
   "outputs": [],
   "source": [
    "feature_importance_df = get_feature_importance_df(model_2, preprocessor)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8JIop4_dJV8"
   },
   "source": [
    "\n",
    "*   We can expect the odds of people who left to increase (the original coeff was positive) for all features.\n",
    "*   OverTime, MonthlyIncome and Age are the strongest predictors.\n",
    "*  JobRole_Research Director and Department_Human Resources are the weakest predictors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r55IMA4jV7s8"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_2 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "QBgcI94-V7y9",
    "outputId": "659111cb-ff0b-4411-de35-d425181dcc65"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(model_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpRzZWEWWUhP"
   },
   "source": [
    "AUC is 0.83 which means that there is a 83% chance that the model will be able to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "ZiPUx4TZWNqD",
    "outputId": "c6ededa7-0432-47df-de9f-48d471c417e6"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(model_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0p2ZKJ5Sd2BJ"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_2 = create_model_summary_row(\"Random Forest\", metrics_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9UjlAL1eDIS"
   },
   "source": [
    "## **Decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "psNQZZfMXFW1",
    "outputId": "99a95fed-c095-4cc4-cc78-6140c0a0a647"
   },
   "outputs": [],
   "source": [
    "# DecisionTree Classifier model\n",
    "model_3 = get_model_pipeline(DecisionTreeClassifier())\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = model_3.predict(X_test)\n",
    "y_pred_tr = model_3.predict(X_train)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_3, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hc42xhpXXFaG",
    "outputId": "4be46b81-1532-4fc4-d2ea-f13abd64261d"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rruCYoqCXFc-",
    "outputId": "170ee60e-a3a5-4422-8dcf-fe27aec033ad"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6J3kcode14C9",
    "outputId": "8d88d89b-c5c5-4e55-b7ba-55d8def62b5c"
   },
   "outputs": [],
   "source": [
    "feature_importance_df = get_feature_importance_df(model_3, preprocessor)\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - Decision Tree')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9i9JEvpecVc"
   },
   "source": [
    "\n",
    "*   We can expect the odds of people who left to increase (the original coeff was positive) for MonthlyIncome, OverTime, DistanceFromHome, NumCompaniesWorked, BusinessTravel_Travel_Frequently, TotalWorkingYears, StockOptionLevel, MaritalStatus_Single, Department_Sales, EnvironmentSatisfaction, DailyRate, EducationField_Marketing, JobInvolvement, YearsSincdLastPromotion, YearsAtCompany, Gender, HourlyRate, Department_Research & Development, PercentSalaryHike, TrainingTimesLastYear.\n",
    "*   Rest columns have coeff equals zero.\n",
    "*   MonthlyIncome is the strongest predictor.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZ-6XZY8XFf3"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_3 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "NYIdALb8XFiv",
    "outputId": "af68befb-38ce-4a93-8881-3fb6f9f50c2c"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(model_3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z5r74yFfX0B"
   },
   "source": [
    "AUC is 0.57 which means that there is a 57% chance that the model will be able to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "09ZI4ms6fXNP",
    "outputId": "6bcc37c9-a996-48af-a007-16395939ea16"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(model_3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nu7K4tezfyyC"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_3 = create_model_summary_row(\"Decision Tree\", metrics_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKC8gDERf786"
   },
   "source": [
    "## **AdaBoost model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "21fcyuvpXFlv",
    "outputId": "97a964e5-dfcb-40af-bca7-35b661429f56"
   },
   "outputs": [],
   "source": [
    "#  AdaBoost Classifier model\n",
    "model_4 = get_model_pipeline(AdaBoostClassifier())\n",
    "model_4.fit(X_train, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = model_4.predict(X_test)\n",
    "y_pred_tr = model_4.predict(X_train)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_4, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JAXAE5Pgab6",
    "outputId": "15a983dc-a1ec-448a-c52a-8a9bf31e3bee"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CyYpA7Ogah5",
    "outputId": "02f0d4d6-713e-46ce-9f23-879f6391d0c6"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rpInliRY2EsQ",
    "outputId": "1b012c99-29aa-4ef4-b418-d3a0d01e4015"
   },
   "outputs": [],
   "source": [
    "feature_importance_df = get_feature_importance_df(model_4, preprocessor)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances -  Ada Boost')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ICBlIWIgc-8"
   },
   "source": [
    "* We can expect the odds of people who left the company to increase (the original coeff was positive) for OverTime, YearsWithCurrManeger, MonthlyIncome, JobSatisfaction, YearsAtCompany, StockOptionLevel, HourlyRate, RelationshipSatisfaction, EnvironmentSatisfaction, Age, DistanceFromHome, JobInvolvement, Department_Research & Development, TrainingTmesLastYear, EducationField_Technical Degree, JobLevel, JobRole_Laboratory Technician, Department_Sales, BusinessTravel_Travel_Frequently, NumCompaniesWorked, BusinessTravel_Non-Travel.\n",
    "* Remaining features had coeff equals zero.\n",
    "* OverTime and YearsWithCurrManager are the strongest predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9twr_2qdgalO"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_4 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "ZqLPt5kAgapa",
    "outputId": "b753a38b-f87d-4d91-b484-9b83e8fa95fe"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(model_4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cspkv67gvX6"
   },
   "source": [
    "AUC is 0.82 which means that there is a 82% chance that the model will be able to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "a6J8evZZhCXb",
    "outputId": "da40c952-0fa4-485c-b16b-563bddfcc830"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(model_4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUtvq_nEhaOU"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_4 = create_model_summary_row(\"Ada Boost\", metrics_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEgdvuxHhjrM"
   },
   "source": [
    "## **Gradient Boosting model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "jd35TRNshIg0",
    "outputId": "26cefeb3-d3ae-452b-9257-126e72745430"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting model\n",
    "model_5 = get_model_pipeline(GradientBoostingClassifier())\n",
    "model_5.fit(X_train, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = model_5.predict(X_test)\n",
    "y_pred_tr = model_5.predict(X_train)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHnDqiVvp-ny",
    "outputId": "ec1a63f1-e72f-4bed-c312-f40f9e73fcb4"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujiDbUN3p-rJ",
    "outputId": "fb6a99db-7ac2-4411-c502-0b1d68f84e7c"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OEIbqReu2Rks",
    "outputId": "48ee62f9-4718-4f4e-efe7-c8da17215d60"
   },
   "outputs": [],
   "source": [
    "feature_importance_df = get_feature_importance_df(model_5, preprocessor)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - Gradient Boosting')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVv49kuRh1sT"
   },
   "source": [
    "* We can expect the odds of workers who left to increase (the original coeff was positive) for almost all features.\n",
    "* PerformanceRating, EducationField_Life Sciences,\n",
    "BusinessTravel_Travel Rarely, EducationField_Human Resources,\n",
    "JobRole_Manager,\n",
    "JobRole_Human Resources,\n",
    "JobRole_Healthcare Representative, EducationField_Other,\n",
    "JobRole_Manufacturing Director,\n",
    "JobRole_Research Scientist,\n",
    "JobRole_Research Director,\n",
    "MaritalStatus_Divorced,\n",
    "MaritalStatus_Married had coeff zero.\n",
    "* MontlyIncome and OverTime are the strongest predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJmryFHsp-uX"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_5 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "6dlwPn3PqSP2",
    "outputId": "9c002af9-f8cf-4727-f704-7962595ae45c"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(model_5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rgHWd0IqYfH"
   },
   "source": [
    "AUC is 0.80 which means that there is a 80% chance that the model will be able to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "TxLmga9CqhtD",
    "outputId": "cd21c58d-1ed4-4b53-faf8-c5427c25e5d9"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(model_5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bnr_XcOwi4T2"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_5 = create_model_summary_row(\"Gradeint Boosting\", metrics_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXh8zgQDjCSE"
   },
   "source": [
    "## **XGBoosing model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "8-babSulqkTP",
    "outputId": "1ffa4d1a-1fe2-4483-ba02-a6f9ab6de878"
   },
   "outputs": [],
   "source": [
    "# XGB model\n",
    "model_6 = get_model_pipeline(XGBClassifier())\n",
    "model_6.fit(X_train, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = model_6.predict(X_test)\n",
    "y_pred_tr = model_6.predict(X_train)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_6, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_J_orsg8q15S",
    "outputId": "d8481b98-b6ae-410f-aa73-a34ea1fc2486"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pKzZDqLfq18c",
    "outputId": "d3457c72-7154-42e0-f1b1-36bf4e8a94d6"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qfLIDyQZ2e-P",
    "outputId": "ae78c076-cb17-4633-9097-b88551aead02"
   },
   "outputs": [],
   "source": [
    "feature_importance_df = get_feature_importance_df(model_6, preprocessor)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - XGBoost')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JemfP0SgjSt_"
   },
   "source": [
    "* We can expect the odds of people who left to increase (the original coeff was positive) for almost all features.\n",
    "* PerformanceRating, EducationField_Human Resources, Department_Human Resources, JobRole_Healthcare Representative, JobRole_Human Resources, JobRole_Manufacturing Director and JobRole_Research Director have coeff equals to zero.\n",
    "* Overtime and JobRole_Sales Executive are the strongest predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTcueJvcq1_Y"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_6 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "2XyIBrRiq2CB",
    "outputId": "175a7189-39a2-49b5-810b-781fd96dc49c"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(model_6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOkkJ0Eurvdi"
   },
   "source": [
    "AUC is 0.79 which means that there is a 79% chance that the model will be able to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "uyuyUR0Tq2Eo",
    "outputId": "f2179328-1b64-4d6d-b19d-3ddeba9f080b"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(model_6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gthPGTASk78s"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_6 = create_model_summary_row(\"XGBoosting\", metrics_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maOmDQmHlGYT"
   },
   "source": [
    "## **CatBoost model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QY7r-t6IrxaT"
   },
   "outputs": [],
   "source": [
    "# CatBoost classifier model\n",
    "model_7 = get_model_pipeline(CatBoostClassifier())\n",
    "model_7.fit(X_train, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = model_7.predict(X_test)\n",
    "y_pred_tr = model_7.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "EJEjEKVFoNNo",
    "outputId": "a31bbb1d-82e4-4c7f-f2dd-c441fe44827e"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_7, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(model_7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-eNqbjqsCaT",
    "outputId": "5d7e5870-5cd1-47ba-ccff-a5e6f27c0f66"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1net4bhjsCdN",
    "outputId": "c284442b-a20d-4631-ccf2-76f8848f534b"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8OlV6ul02p_a",
    "outputId": "cce61064-b252-42f6-bf62-638d1f804360"
   },
   "outputs": [],
   "source": [
    "feature_importance_df = get_feature_importance_df(model_7, preprocessor)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - Cat Boost')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lhDmPh1lqIx"
   },
   "source": [
    "* We can expect the odds of people who left to increase (the original coeff was positive) for almost all features.\n",
    "* EducationField_Human Resources has coeff equals to zero.\n",
    "* OverTime, MonthlyIncome and Age are the strongest predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWWanG7csCfv"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_7 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "WaAPjZD1sCi9",
    "outputId": "5d7c31cb-0fe1-413b-b7fe-51654a12e69d"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(model_7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RyXYz0gtL0c"
   },
   "source": [
    "AUC is 0.82 which means that there is a 82% chance that the model will be able to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "2UONndLDsLZh",
    "outputId": "4893cdb6-05f1-4474-c874-f43785598818"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(model_7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brBZGgSomKuc"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_7 = create_model_summary_row(\"CatBoost\", metrics_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i5a-Aj1mUCa"
   },
   "source": [
    "## **Model summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "XEpozLkLmYRj",
    "outputId": "e1e9ab59-462f-4349-c79b-4be0e99e9c71"
   },
   "outputs": [],
   "source": [
    "# Add all results to dataframe\n",
    "results = pd.DataFrame(columns=['model', 'tp', 'tn', 'fp', 'fn', 'correct', 'incorrect',\n",
    "                                  'accuracy_train', 'accuracy_test', 'precision_train', 'precision_test', 'recall_train', 'recall_test', 'f1_train', 'f1_test', 'roc_auc', 'avg_pre'])\n",
    "new_rows = pd.DataFrame([row_1, row_2, row_3, row_4, row_5, row_6, row_7])\n",
    "results = pd.concat([results, new_rows], ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvxtdfaR7tBc"
   },
   "source": [
    "## **Genaral overwiew of models**\n",
    "\n",
    "* Logistic Regression performs the best overall with a strong balance between precision and recall, making it the most robust choice. It is well-suited for imbalanced classification with minimal overfitting.\n",
    "\n",
    "* Random Forest is overfitting—perfect precision on train and test, but almost no true positives captured (low recall). Poor generalization and poor F1.\n",
    "\n",
    "* Single tree is underperforming. Although interpretable, it lacks predictive power and likely overfits.\n",
    "\n",
    "* AdaBoost is precise but fails to capture actual attrition cases (low recall). Performs similarly to Random Forest but worse than Logistic Regression.\n",
    "\n",
    "* Gradient Boosting - decent recall and ROC AUC, better than AdaBoost, but still significantly underperforms compared to Logistic Regression. Potential for improvement with tuning.\n",
    "\n",
    "* XGBoost shows promise—balanced performance and better recall than other tree-based models. Still trails behind Logistic Regression in F1 and ROC AUC.\n",
    "\n",
    "* CatBoost is stable and good at precision but lacks strong recall. Similar to AdaBoost and Gradient Boosting.\n",
    "\n",
    "# **To sum up, Logistic Regression will be taken into account in further analysis.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejlEFWynWagX"
   },
   "source": [
    "# **Logistic regression with undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5mrKW3NRGQDr",
    "outputId": "a2b54233-202b-4122-c042-5d3105cb0675"
   },
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "\n",
    "# Extract feature names from each transformer in the ColumnTransformer\n",
    "for name, transformer, columns in preprocessor.transformers_:\n",
    "    if name != 'remainder':\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            transformed_names = transformer.get_feature_names_out(columns)\n",
    "        else:\n",
    "            transformed_names = columns\n",
    "        feature_names.extend(transformed_names)\n",
    "\n",
    "m1 = model_1.named_steps['model']\n",
    "importances = abs(m1.coef_[0])\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.barh(feature_importance_df['Feature'][::-1], feature_importance_df['Importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - Logistic regression')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3R4BboVpH6oo"
   },
   "outputs": [],
   "source": [
    "# For further analysis, only the numerical features with the greatest positive feature importance will be be used: 'OverTime', 'YearsAtCompany', 'JobSatisfaction', 'EnvironmentSatisfaction', 'DistanceFromHome', 'YearsWithCurrManager', 'YearsInCurrentRole', 'NumCompaniesWorked', 'TotalWorkingYears', 'YearsSinceLastPromotion'\n",
    "# All categorical features will be considered\n",
    "num_shrink =['OverTime', 'YearsAtCompany', 'JobSatisfaction', 'EnvironmentSatisfaction', 'DistanceFromHome', 'YearsWithCurrManager', 'YearsInCurrentRole', 'NumCompaniesWorked', 'TotalWorkingYears', 'YearsSinceLastPromotion']\n",
    "attr = list(num_shrink) + list(cat_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8p45kq1_-l_"
   },
   "outputs": [],
   "source": [
    "preprocessor_shrink = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_shrink),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_attr_shrink)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DMhog3UKrzx"
   },
   "outputs": [],
   "source": [
    "X_train_top = X_train[attr]\n",
    "X_test_top = X_test[attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgSliLFsZNns"
   },
   "outputs": [],
   "source": [
    "undersample_pipeline = ImbPipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor_shrink),\n",
    "    (\"undersample\", RandomUnderSampler(random_state=42)),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "SHBgrJ4ULm1Q",
    "outputId": "0e3eb901-c4c7-449b-a100-7597df647a79"
   },
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "undersample_pipeline.fit(X_train_top, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = undersample_pipeline.predict(X_test_top)\n",
    "y_pred_tr = undersample_pipeline.predict(X_train_top)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(undersample_pipeline, X_train_top, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(undersample_pipeline, X_test_top, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFPP6v1LMTE9",
    "outputId": "0fcc1a9b-a87b-4bbc-c97e-b19c3263cf14"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibc84pYHMcm0",
    "outputId": "39d482cd-8f53-4c05-d298-324bb3df92f6"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4beWqQ3QND-O"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_8 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "sosjgkz9NT1F",
    "outputId": "abf0b970-14c8-4c40-8dd0-93e0df646081"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(undersample_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "H0Flg6gsNcxN",
    "outputId": "d245e718-97a9-47fd-8ec3-4d5c28bb565e"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(undersample_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDkbu2CtJ6RB"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_8 = create_model_summary_row(\"Logistic regression with undersampling\", metrics_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUxYUnVmKEYq"
   },
   "source": [
    "# **Logistic Regression with oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt4Hh-eqZUaC"
   },
   "outputs": [],
   "source": [
    "oversample_pipeline = ImbPipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor_shrink),\n",
    "    (\"oversample\", RandomOverSampler(random_state=42)),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "uQGNHb-FNwkT",
    "outputId": "f8083b2b-7ad2-4fd3-f5ef-f27db9251534"
   },
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "oversample_pipeline.fit(X_train_top, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = oversample_pipeline.predict(X_test_top)\n",
    "y_pred_tr = oversample_pipeline.predict(X_train_top)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(oversample_pipeline, X_train_top, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(oversample_pipeline, X_test_top, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XALhwMD1N-I6",
    "outputId": "725cb842-e710-406d-fdc7-4f014338bc95"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDNLVHoiORGk",
    "outputId": "d2af9c96-5b10-4a11-a475-15ac34d3deb3"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M5ZWehsOU5z"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_9 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "3dmxFWm9OZOU",
    "outputId": "e587718e-7144-42a4-d322-e1ef5e064024"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(oversample_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "E2VWw6JgOexD",
    "outputId": "4b6d4519-f695-448e-eaa1-dd374c6b65ac"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(oversample_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWF1nRc6KZLr"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_9 = create_model_summary_row(\"Logistic regression with oversampling\", metrics_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC_dSR5_Kzdf"
   },
   "source": [
    "# **Logistic regression with SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn==1.3.2 imbalanced-learn==0.11.0 numpy==1.23.5 pandas==1.5.3 --quiet --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSyNJ4dvZmSE"
   },
   "outputs": [],
   "source": [
    "smote_pipeline = ImbPipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor_shrink),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "nUjzyUjrOuc7",
    "outputId": "a6410165-a318-40b5-db5a-8e82a1fc8842"
   },
   "outputs": [],
   "source": [
    "#Logistic regression model\n",
    "smote_pipeline.fit(X_train_top, y_train)\n",
    "\n",
    "# Model performance evaluation for test and train set\n",
    "y_pred = smote_pipeline.predict(X_test_top)\n",
    "y_pred_tr = smote_pipeline.predict(X_train_top)\n",
    "\n",
    "# Confusion matrix for train set\n",
    "print(\"Confusion matrix for train set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(smote_pipeline, X_train_top, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "print(\"Confusion matrix for test set: \")\n",
    "ConfusionMatrixDisplay.from_estimator(smote_pipeline, X_test_top, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1Da42QXOug9",
    "outputId": "3c5b92cc-9be1-477d-c3a2-a36f6594311c"
   },
   "outputs": [],
   "source": [
    "# Classification report for test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kWp0ceEOukS",
    "outputId": "1a7575b3-8c5c-4f1a-b1dc-3a55f47a639a"
   },
   "outputs": [],
   "source": [
    "# Classification report for train set\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ly65i7vOuoi"
   },
   "outputs": [],
   "source": [
    "# Gather some metrics for future comparison of models performance\n",
    "metrics_10 = compute_classification_metrics(y_train, y_pred_tr, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "w4aQ3C5OPJy7",
    "outputId": "760a0fa8-d6a1-46fa-eb51-fe6cf2bdd16e"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve(smote_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "RElGqSfIPQsk",
    "outputId": "db8e9330-456e-423b-c6c7-ae7003f49cbf"
   },
   "outputs": [],
   "source": [
    "# Precision-Recall curve\n",
    "plot_precision_recall_curve(smote_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHEW7Ea8LZOf"
   },
   "outputs": [],
   "source": [
    "# Row with model\n",
    "row_10 = create_model_summary_row(\"Logistic regression with SMOTE\", metrics_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHyEtIvvUpl1"
   },
   "source": [
    "## **Best model summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "HlsTM24wwomw",
    "outputId": "8a0b8399-7702-4f00-8e04-9926a5e7a265"
   },
   "outputs": [],
   "source": [
    "new_rows = pd.DataFrame([row_8, row_9, row_10])\n",
    "results = pd.concat([results, new_rows], ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "m0rG3HaPmSmH",
    "outputId": "e2173b1b-685e-455d-ff44-b767ee31944c"
   },
   "outputs": [],
   "source": [
    "# Roc for all mogistic regression models\n",
    "models = models = {\n",
    "    \"Logistic Regression\": model_1,\n",
    "    \"Logistic regression with undersampling\": undersample_pipeline,\n",
    "    \"Logistic regression with oversampling\": oversample_pipeline,\n",
    "    \"Logistic regression with SMOTE\": smote_pipeline\n",
    "}\n",
    "plt.figure(figsize=(12, 8))\n",
    "for name, model in models.items():\n",
    "    RocCurveDisplay.from_estimator(model, X_test, y_test, name=name, ax=plt.gca())\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG7QRReRowFV"
   },
   "source": [
    "**Models summary**\n",
    "\n",
    "* Baseline Logistic regression model has the highest test accuracy, highest precision and F1 score. It has good ROC AUC and average precision. The drawback is that the recall is lowest - misses more positive cases than others.\n",
    "* Undersampling model has the highest recall but the lowest precision. It has moderate F! and highest ROC AUC. Seems to be the best option for maximizing recall.\n",
    "* Oversampling model results are similar to indersampling model but it has slightly lower performance overall.\n",
    "* SMOTE model is a balanced option between undersampling and oversampling. It has slightly better precision and F1 than oversampling. \n",
    "\n",
    "* **Undersampling model** is the best for attrition detection. It has the highest recall - correctly detects almost 78% of attrition cases. It has the best ROC AUC 77%. Althoug it has lower precision, in attrition detection false positives are less harmful than false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlNDrNhryxYp"
   },
   "source": [
    "## **Making a predictive system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpwBvkjZy__G",
    "outputId": "a9c6ba6e-892e-4ef3-f4de-4b90e2a066c5"
   },
   "outputs": [],
   "source": [
    "input_data = (0, 9, 4, 3, 2, 3, 7, 4, 12, 7, 'Travel_Rarely', 'Sales', 'Medical', 'Sales Executive', 'Single')\n",
    "\n",
    "# Changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# Reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "example = pd.DataFrame(input_data_reshaped)\n",
    "example.columns = X_test_top.columns\n",
    "\n",
    "best_model = undersample_pipeline\n",
    "\n",
    "prediction = best_model.predict(example)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('The person will stay.')\n",
    "else:\n",
    "  print('The person will leave.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7nhMkEx4hDp"
   },
   "source": [
    "## **Saving the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvsxzKvr4nKu"
   },
   "outputs": [],
   "source": [
    "filename = './model/trained_model.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6H6T8P04teO"
   },
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uf5za1Xh4w6i",
    "outputId": "3d316c1f-c3f6-4916-9ace-8ac51d5b65c8"
   },
   "outputs": [],
   "source": [
    "input_data = (1, 9, 4, 3, 2, 3, 7, 4, 12, 7, 'Travel_Rarely', 'Sales', 'Medical', 'Sales Executive', 'Married')\n",
    "\n",
    "# Changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "example = pd.DataFrame(input_data_reshaped)\n",
    "example.columns = X_test_top.columns\n",
    "\n",
    "prediction = loaded_model.predict(example)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('The person will stay.')\n",
    "else:\n",
    "  print('The person will leave.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.T"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "XDNNRvQnKYqg",
    "CDle1tyKHI9_",
    "77A_k1rWIhST",
    "Ojdw8MvqM94e"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
